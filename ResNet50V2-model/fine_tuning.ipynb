{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.1\n",
      "3.9.11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread_collection\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "from platform import python_version\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(python_version())\n",
    "\n",
    "from keras import layers\n",
    "#from keras.applications import DenseNet121   #우리는 ResNet50을 사용하려 한다.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pydicom as dicom\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "folder_name = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\\"\n",
    "\n",
    "# Constants\n",
    "SEED = 42\n",
    "NO_CHANNEL = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "PATH= folder_name\n",
    "\n",
    "RESNET_WEIGHT_FULLPATH = f'{folder_name}resnet50_weights_tf.h5'\n",
    "TRAIN_CSV_FULLPATH = 'C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\stage_2_train.csv'\n",
    "#TEST_CSV_FULLPATH = 'C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\archive\\\\MIL_test.csv'\n",
    "TRAIN_IMG_PATH = PATH + 'train\\\\'\n",
    "TEST_IMG_PATH = PATH + 'test\\\\'\n",
    "\n",
    "random.seed(SEED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the same as the images imported\n",
    "print(\"학습/검증 데이터셋에서 정상 이미지 갯수 : \" , len(normal_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 불량하거나 구분할 수 없는 CT 이미지 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뇌출혈 이미지셋 크기 : 109428 장\n"
     ]
    }
   ],
   "source": [
    "# 출혈 이미지 데이터셋 경로\n",
    "col_dir = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\hemorrhage\\\\*.jpg\" \n",
    "# 이미지 갯수 확인\n",
    "images = imread_collection(col_dir)\n",
    "\n",
    "hemorrhage_size = len(images)\n",
    "\n",
    "print(f\"뇌출혈 이미지셋 크기 : {hemorrhage_size} 장\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상인 이미지셋 크기 : 109428 장\n"
     ]
    }
   ],
   "source": [
    "# 정상 이미지 데이터셋 경로\n",
    "col_dir = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\normal\\\\*.jpg\" \n",
    "# 이미지 갯수 확인\n",
    "images = imread_collection(col_dir)\n",
    "\n",
    "normal_size = len(images)\n",
    "\n",
    "print(f\"정상인 이미지셋 크기 : {normal_size} 장\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뇌출혈 이미지셋 크기 : 5814 장\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "hem_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\hemorrhage\"\n",
    "nor_path = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\normal\"\n",
    "\n",
    "#뇌출혈 이미지에서 15KB 미만 파일들(뇌가 아주 작게 잘린 말단면들) 제거\n",
    "with os.scandir(hem_path) as it:\n",
    "    for entry in it:\n",
    "        if entry.stat().st_size//1024 < 15:\n",
    "            remove(f\"{hem_path}\\\\{entry.name}\")\n",
    "\n",
    "# 삭제한 이미지 갯수 출력\n",
    "col_dir = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\hemorrhage\\\\*.jpg\" \n",
    "images = imread_collection(col_dir)\n",
    "hemorrhage_size_rest = len(images)\n",
    "print(f\"뇌출혈 이미지셋 크기 : {hemorrhage_size-hemorrhage_size_rest} 장\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뇌출혈 이미지셋 크기 : 22779 장\n"
     ]
    }
   ],
   "source": [
    "#정상 이미지에서 15KB 미만 파일들(뇌가 아주 작게 잘린 말단면들) 제거\n",
    "with os.scandir(nor_path) as it:\n",
    "    for entry in it:\n",
    "        if entry.stat().st_size//1024 < 15:\n",
    "            remove(f\"{nor_path}\\\\{entry.name}\")\n",
    "\n",
    "# 삭제한 이미지 갯수 출력\n",
    "col_dir = \"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified\\\\normal\\\\*.jpg\" \n",
    "images = imread_collection(col_dir)\n",
    "normal_size_rest = len(images)\n",
    "print(f\"뇌출혈 이미지셋 크기 : {normal_size-normal_size_rest} 장\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152212 images belonging to 2 classes.\n",
      "Found 38051 images belonging to 2 classes.\n",
      "Found 2210 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "SIZE = 224\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2 )\n",
    "train_generator = train_datagen.flow_from_directory('C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified', subset=\"training\", shuffle = True, target_size=(SIZE,SIZE), batch_size=BATCH_SIZE, class_mode = 'binary' )\n",
    "validation_generator = train_datagen.flow_from_directory('C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\train\\\\classified', subset=\"validation\", shuffle = True, target_size=(SIZE,SIZE), batch_size=BATCH_SIZE ,class_mode = 'binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255 , validation_split=0.0,)\n",
    "test_generator = test_datagen.flow_from_directory('C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\test\\\\classified', shuffle = False, target_size=(SIZE,SIZE), batch_size=BATCH_SIZE,class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (SIZE,SIZE)\n",
    "NUM_CLASSES = 1\n",
    "METRICS = [tf.keras.metrics.BinaryAccuracy()]\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 증강\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "   tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "   tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "   #tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "   #tf.keras.layers.experimental.preprocessing.RandomWidth(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50V2(include_top = False , weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7, 7, 2048)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_generator))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특징 추출\n",
    "\n",
    "#### 컨볼루션 베이스 모델 고정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50v2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, None, None,  0           []                               \n",
      "                                 3)]                                                              \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, None, None,   0           ['input_10[0][0]']               \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, None, None,   9472        ['conv1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, None, None,   0           ['conv1_conv[0][0]']             \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, None, None,   0           ['pool1_pad[0][0]']              \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, None, None,   256        ['pool1_pool[0][0]']             \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, None, None,   0          ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                        64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, None, None,   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, None, None,   0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, None, None,   0          ['conv2_block1_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, None, None,   0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                256)                              'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, None, None,   0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, None, None,   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, None, None,   0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, None, None,   0          ['conv2_block2_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, None, None,   0           ['conv2_block1_out[0][0]',       \n",
      "                                256)                              'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, None, None,   0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, None, None,   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                64)                              ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, None, None,   0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                           64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, None, None,   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, None, None,   256        ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                       64)                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, None, None,   0          ['conv2_block3_2_bn[0][0]']      \n",
      " n)                             64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooling2D  (None, None, None,   0          ['conv2_block2_out[0][0]']       \n",
      " )                              256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, None, None,   16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, None, None,   0           ['max_pooling2d_12[0][0]',       \n",
      "                                256)                              'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, None, None,   1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, None, None,   0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                        256)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, None, None,   32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, None, None,   0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, None, None,   0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, None, None,   131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, None, None,   0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                512)                              'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, None, None,   0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, None, None,   0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, None, None,   0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, None, None,   0           ['conv3_block1_out[0][0]',       \n",
      "                                512)                              'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, None, None,   0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, None, None,   0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, None, None,   0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, None, None,   0           ['conv3_block2_out[0][0]',       \n",
      "                                512)                              'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, None, None,   0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, None, None,   65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                128)                             ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, None, None,   0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, None, None,   0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                           128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, None, None,   147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, None, None,   512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                       128)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, None, None,   0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                             128)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, None, None,   0          ['conv3_block3_out[0][0]']       \n",
      " )                              512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, None, None,   66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, None, None,   0           ['max_pooling2d_13[0][0]',       \n",
      "                                512)                              'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, None, None,   2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                  512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, None, None,   0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                        512)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, None, None,   131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, None, None,   0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, None, None,   0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, None, None,   525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                1024)                            ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, None, None,   0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                1024)                             'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, None, None,   0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, None, None,   0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, None, None,   0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, None, None,   0           ['conv4_block1_out[0][0]',       \n",
      "                                1024)                             'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, None, None,   0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, None, None,   0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, None, None,   0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, None, None,   0           ['conv4_block2_out[0][0]',       \n",
      "                                1024)                             'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, None, None,   0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, None, None,   0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, None, None,   0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, None, None,   0           ['conv4_block3_out[0][0]',       \n",
      "                                1024)                             'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, None, None,   0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, None, None,   0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, None, None,   0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, None, None,   0           ['conv4_block4_out[0][0]',       \n",
      "                                1024)                             'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, None, None,   0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, None, None,   262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                256)                             ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, None, None,   0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, None, None,   0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                           256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, None, None,   589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, None, None,   1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                       256)                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, None, None,   0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                             256)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, None, None,   0          ['conv4_block5_out[0][0]']       \n",
      " )                              1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, None, None,   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                1024)                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, None, None,   0           ['max_pooling2d_14[0][0]',       \n",
      "                                1024)                             'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, None, None,   4096       ['conv4_block6_out[0][0]']       \n",
      " ormalization)                  1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, None, None,   0          ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                        1024)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, None, None,   524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, None, None,   0          ['conv5_block1_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, None, None,   0          ['conv5_block1_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, None, None,   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                2048)                            ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, None, None,   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                2048)                             'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, None, None,   8192       ['conv5_block1_out[0][0]']       \n",
      " ormalization)                  2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, None, None,   0          ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                        2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, None, None,   1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, None, None,   0          ['conv5_block2_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, None, None,   0          ['conv5_block2_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, None, None,   0           ['conv5_block1_out[0][0]',       \n",
      "                                2048)                             'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, None, None,   8192       ['conv5_block2_out[0][0]']       \n",
      " ormalization)                  2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, None, None,   0          ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                        2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, None, None,   1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                512)                             ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, None, None,   0          ['conv5_block3_1_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, None, None,   0          ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                           512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, None, None,   2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, None, None,   2048       ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                       512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, None, None,   0          ['conv5_block3_2_bn[0][0]']      \n",
      " n)                             512)                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, None, None,   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, None, None,   0           ['conv5_block2_out[0][0]',       \n",
      "                                2048)                             'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, None, None,   8192        ['conv5_block3_out[0][0]']       \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, None, None,   0           ['post_bn[0][0]']                \n",
      "                                2048)                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 기본 모델 아키텍처를 살펴봅니다.\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류 층을 맨 위에 추가하기\n",
    "##### 특성 블록에서 예측을 생성하기 위해 tf.keras.layers.GlobalAveragePooling2D 레이어를 사용하여 특성을 이미지당 하나의 1280-요소 벡터로 변환하여 5x5 공간 위치에 대한 평균을 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2048)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    }
   ],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid')(prediction_layer(x))\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, None, None, 2048)  23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,566,851\n",
      "Trainable params: 2,051\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2379/2379 [==============================] - 78s 32ms/step - loss: 1.0174 - accuracy: 0.5447\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 1.02\n",
      "initial accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=43c7c9707887ea6277ac1ff15c5e47f45a42c1ac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:q38rt9vt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a673b60814457f919c615b532ccf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">[ResNetV2_tuning], Tue Jul 12 23:11:04 2022</strong>: <a href=\"https://wandb.ai/pypyp/aiinternship/runs/q38rt9vt\" target=\"_blank\">https://wandb.ai/pypyp/aiinternship/runs/q38rt9vt</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220712_231104-q38rt9vt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:q38rt9vt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\실리콘밸리 온라인 인턴십\\wandb\\run-20220712_231537-1mwifg03</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pypyp/aiinternship/runs/1mwifg03\" target=\"_blank\">[ResNetV2_tuning], Tue Jul 12 23:15:37 2022</a></strong> to <a href=\"https://wandb.ai/pypyp/aiinternship\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pypyp/aiinternship/runs/1mwifg03?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1ed9f289c40>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "date = time.strftime('%c', time.localtime(time.time()))\n",
    "\n",
    "%env WANDB_API_KEY=43c7c9707887ea6277ac1ff15c5e47f45a42c1ac\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"aiinternship\", entity=\"pypyp\" , name = \"[ResNetV2_tuning], \" + date , config = {\"learning_rate\": base_learning_rate,\"epochs\": initial_epochs,\"batch_size\": BATCH_SIZE,\"drop_out\" : 0.5,\"train_data_num\" : 152212,\"valid_data_num\" : 38051} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9514/9514 [==============================] - 398s 42ms/step - loss: 0.6056 - binary_accuracy: 0.6988 - val_loss: 0.5103 - val_binary_accuracy: 0.7492 - _timestamp: 1657635751.0000 - _runtime: 409.0000\n",
      "Epoch 2/10\n",
      "9514/9514 [==============================] - 408s 43ms/step - loss: 0.5252 - binary_accuracy: 0.7350 - val_loss: 0.5025 - val_binary_accuracy: 0.7538 - _timestamp: 1657636159.0000 - _runtime: 817.0000\n",
      "Epoch 3/10\n",
      "9514/9514 [==============================] - 391s 41ms/step - loss: 0.5192 - binary_accuracy: 0.7413 - val_loss: 0.5013 - val_binary_accuracy: 0.7477 - _timestamp: 1657636550.0000 - _runtime: 1208.0000\n",
      "Epoch 4/10\n",
      "9514/9514 [==============================] - 394s 41ms/step - loss: 0.5170 - binary_accuracy: 0.7419 - val_loss: 0.4969 - val_binary_accuracy: 0.7546 - _timestamp: 1657636944.0000 - _runtime: 1602.0000\n",
      "Epoch 5/10\n",
      "9514/9514 [==============================] - 392s 41ms/step - loss: 0.5164 - binary_accuracy: 0.7423 - val_loss: 0.4968 - val_binary_accuracy: 0.7595 - _timestamp: 1657637336.0000 - _runtime: 1994.0000\n",
      "Epoch 6/10\n",
      "9514/9514 [==============================] - 395s 42ms/step - loss: 0.5160 - binary_accuracy: 0.7426 - val_loss: 0.4950 - val_binary_accuracy: 0.7625 - _timestamp: 1657637731.0000 - _runtime: 2389.0000\n",
      "Epoch 7/10\n",
      "9514/9514 [==============================] - 387s 41ms/step - loss: 0.5140 - binary_accuracy: 0.7451 - val_loss: 0.4941 - val_binary_accuracy: 0.7583 - _timestamp: 1657638119.0000 - _runtime: 2777.0000\n",
      "Epoch 8/10\n",
      "9514/9514 [==============================] - 392s 41ms/step - loss: 0.5151 - binary_accuracy: 0.7439 - val_loss: 0.4946 - val_binary_accuracy: 0.7575 - _timestamp: 1657638511.0000 - _runtime: 3169.0000\n",
      "Epoch 9/10\n",
      "9514/9514 [==============================] - 394s 41ms/step - loss: 0.5148 - binary_accuracy: 0.7449 - val_loss: 0.4970 - val_binary_accuracy: 0.7606 - _timestamp: 1657638904.0000 - _runtime: 3562.0000\n",
      "Epoch 10/10\n",
      "9514/9514 [==============================] - 382s 40ms/step - loss: 0.5137 - binary_accuracy: 0.7451 - val_loss: 0.4943 - val_binary_accuracy: 0.7582 - _timestamp: 1657639286.0000 - _runtime: 3944.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    verbose = 1 ,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  190\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, None, None, 2048)  23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 2049      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,566,851\n",
      "Trainable params: 20,561,923\n",
      "Non-trainable params: 3,004,928\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9514/9514 [==============================] - 634s 66ms/step - loss: 0.4000 - accuracy: 0.8187 - val_loss: 0.3673 - val_accuracy: 0.8337\n",
      "Epoch 11/20\n",
      "9514/9514 [==============================] - 616s 65ms/step - loss: 0.3468 - accuracy: 0.8492 - val_loss: 0.3483 - val_accuracy: 0.8457\n",
      "Epoch 12/20\n",
      "9514/9514 [==============================] - 649s 68ms/step - loss: 0.3250 - accuracy: 0.8606 - val_loss: 0.3407 - val_accuracy: 0.8518\n",
      "Epoch 13/20\n",
      "9514/9514 [==============================] - 681s 72ms/step - loss: 0.3118 - accuracy: 0.8669 - val_loss: 0.3242 - val_accuracy: 0.8633\n",
      "Epoch 14/20\n",
      "9514/9514 [==============================] - 671s 71ms/step - loss: 0.3004 - accuracy: 0.8730 - val_loss: 0.3258 - val_accuracy: 0.8647\n",
      "Epoch 15/20\n",
      "9514/9514 [==============================] - 663s 70ms/step - loss: 0.2900 - accuracy: 0.8785 - val_loss: 0.3169 - val_accuracy: 0.8663\n",
      "Epoch 16/20\n",
      "9514/9514 [==============================] - 630s 66ms/step - loss: 0.2811 - accuracy: 0.8827 - val_loss: 0.3146 - val_accuracy: 0.8701\n",
      "Epoch 17/20\n",
      "9514/9514 [==============================] - 658s 69ms/step - loss: 0.2721 - accuracy: 0.8867 - val_loss: 0.3183 - val_accuracy: 0.8715\n",
      "Epoch 18/20\n",
      "9514/9514 [==============================] - 673s 71ms/step - loss: 0.2658 - accuracy: 0.8895 - val_loss: 0.3243 - val_accuracy: 0.8707\n",
      "Epoch 19/20\n",
      "9514/9514 [==============================] - 672s 71ms/step - loss: 0.2559 - accuracy: 0.8942 - val_loss: 0.3125 - val_accuracy: 0.8722\n",
      "Epoch 20/20\n",
      "9514/9514 [==============================] - 658s 69ms/step - loss: 0.2505 - accuracy: 0.8962 - val_loss: 0.3453 - val_accuracy: 0.8643\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_generator,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\model\\\\resnet50_0713_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\model\\\\resnet50_0713_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 5\n",
    "base_learning_rate = 0.000125\n",
    "base_learning_rate = base_learning_rate/5\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_API_KEY=43c7c9707887ea6277ac1ff15c5e47f45a42c1ac\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1jpr3vpz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe3bc3661bc4d6cbda2244c060b4905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='150.378 MB of 150.378 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>binary_accuracy</td><td>▃▅█▅▁</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>loss</td><td>█▅▃▁▆</td></tr><tr><td>val_binary_accuracy</td><td>▆▂█▁▆</td></tr><tr><td>val_loss</td><td>▄▁▆█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>1</td></tr><tr><td>best_val_loss</td><td>0.25999</td></tr><tr><td>binary_accuracy</td><td>0.93388</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.17351</td></tr><tr><td>val_binary_accuracy</td><td>0.89861</td></tr><tr><td>val_loss</td><td>0.26045</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">[ResNetV2_tuning], Wed Jul 13 13:04:45 2022</strong>: <a href=\"https://wandb.ai/pypyp/aiinternship/runs/1jpr3vpz\" target=\"_blank\">https://wandb.ai/pypyp/aiinternship/runs/1jpr3vpz</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220713_130445-1jpr3vpz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1jpr3vpz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\실리콘밸리 온라인 인턴십\\wandb\\run-20220713_143841-xwjc1ktm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pypyp/aiinternship/runs/xwjc1ktm\" target=\"_blank\">[ResNetV2_tuning], Wed Jul 13 14:38:41 2022</a></strong> to <a href=\"https://wandb.ai/pypyp/aiinternship\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pypyp/aiinternship/runs/xwjc1ktm?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x24acbc08d60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "date = time.strftime('%c', time.localtime(time.time()))\n",
    "\n",
    "%env WANDB_API_KEY=43c7c9707887ea6277ac1ff15c5e47f45a42c1ac\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project=\"aiinternship\", entity=\"pypyp\" , name = \"[ResNetV2_tuning], \" + date , config = {\"learning_rate\": base_learning_rate,\"epochs\": initial_epochs,\"batch_size\": BATCH_SIZE,\"drop_out\" : 0.5,\"train_data_num\" : 152212,\"valid_data_num\" : 38051} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, None, None, 2048)  23564800  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 2049      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,566,849\n",
      "Trainable params: 14,445,569\n",
      "Non-trainable params: 9,121,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = loaded_model.get_layer(\"resnet50v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  190\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:len(base_model.layers)]:\n",
    "  layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "loaded_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/9514 [====>.........................] - ETA: 13:00 - loss: 0.1841 - binary_accuracy: 0.9110"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\실리콘밸리 온라인 인턴십\\fine_tuning.ipynb 셀 46\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/%EC%8B%A4%EB%A6%AC%EC%BD%98%EB%B0%B8%EB%A6%AC%20%EC%98%A8%EB%9D%BC%EC%9D%B8%20%EC%9D%B8%ED%84%B4%EC%8B%AD/fine_tuning.ipynb#ch0000045?line=0'>1</a>\u001b[0m history_fine \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/%EC%8B%A4%EB%A6%AC%EC%BD%98%EB%B0%B8%EB%A6%AC%20%EC%98%A8%EB%9D%BC%EC%9D%B8%20%EC%9D%B8%ED%84%B4%EC%8B%AD/fine_tuning.ipynb#ch0000045?line=1'>2</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49minitial_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/%EC%8B%A4%EB%A6%AC%EC%BD%98%EB%B0%B8%EB%A6%AC%20%EC%98%A8%EB%9D%BC%EC%9D%B8%20%EC%9D%B8%ED%84%B4%EC%8B%AD/fine_tuning.ipynb#ch0000045?line=2'>3</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/%EC%8B%A4%EB%A6%AC%EC%BD%98%EB%B0%B8%EB%A6%AC%20%EC%98%A8%EB%9D%BC%EC%9D%B8%20%EC%9D%B8%ED%84%B4%EC%8B%AD/fine_tuning.ipynb#ch0000045?line=3'>4</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[WandbCallback()])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:163\u001b[0m, in \u001b[0;36mpatch_tf_keras.<locals>.new_v2\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mfor\u001b[39;00m cbk \u001b[39min\u001b[39;00m cbks:\n\u001b[0;32m    162\u001b[0m         set_wandb_attrs(cbk, val_data)\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m old_v2(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \n\u001b[0;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[0;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[0;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \n\u001b[0;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_fine = loaded_model.fit(train_generator,\n",
    "                        epochs=initial_epochs,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.save(\"C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\model\\\\resnet50_0712_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2210 images belonging to 2 classes.\n",
      "70/70 [==============================] - 4s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255 , validation_split=0.0,)\n",
    "test_generator = test_datagen.flow_from_directory('C:\\\\Users\\\\user\\\\Desktop\\\\실리콘밸리 온라인 인턴십\\\\rsna-intracranial-hemorrhage-detection\\\\preprocessed\\\\test\\\\classified', shuffle = True , target_size=(SIZE,SIZE), batch_size=2210,class_mode = 'binary')\n",
    "\n",
    "datas , labels = next(iter(test_generator))\n",
    "\n",
    "predictions = loaded_model.predict(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if predictions[i] < 0.5:\n",
    "        predictions[i] = 0\n",
    "    else:\n",
    "        predictions[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = tf.math.confusion_matrix(\n",
    "    labels,\n",
    "    predictions,\n",
    "    num_classes=2,\n",
    "    weights=None,\n",
    "    dtype=tf.dtypes.int32,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = conf_mat/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(conf_mat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = np.array(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43393665, 0.06606335],\n",
       "       [0.03438914, 0.46561086]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns   \n",
    "group_names = [['TN','FP'],['FN','TP']]\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_mat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_mat.shape[0]):\n",
    "    for j in range(conf_mat.shape[1]):\n",
    "        ax.text(x=j, y=i,s=group_names[i][j] + \"\\n\\n\"+f\"{round(100*conf_mat[i, j],2)}%\", va='center', ha='center', size='xx-large')\n",
    "accuracy = round(100*(conf_mat[0, 0]+conf_mat[1, 1]),2)\n",
    "precision = round(100*conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[0, 1]),2)\n",
    "recall = round(100*conf_mat[0, 0]/(conf_mat[0, 0] + conf_mat[1, 0]),2)\n",
    "f1_score = round(2*(precision*recall)/(precision+recall),2)\n",
    "#plt.xlabel(f'Predictions \\n\\naccuracy : {accuracy}\\n\\n precision : {precision}%\\n\\nrecall : {recall}%\\n\\nf1-score : {f1_score}%', fontsize=18)\n",
    "plt.xlabel(f'Predictions \\n\\naccuracy : {accuracy}%', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
